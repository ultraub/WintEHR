#!/bin/bash
#
# MedGenEMR Unified Deployment Script
# Supports: Local (Docker), AWS, Azure deployments
# Features: Complete data generation with Organizations, Providers, and clean patient names
#

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# Default Configuration
PATIENT_COUNT=30
PROVIDER_COUNT=10
ORGANIZATION_COUNT=5
DEPLOYMENT_ENV="local"  # local, aws, azure
CLEAN_NAMES=true
INCLUDE_DICOM=true
FRESH_DEPLOY=false
VERBOSE=false

# Helper functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_section() {
    echo -e "\n${PURPLE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${PURPLE}  $1${NC}"
    echo -e "${PURPLE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"
}

# Show usage
usage() {
    cat << EOF
ğŸ¥ MedGenEMR Unified Deployment Script

Usage: $0 [OPTIONS]

OPTIONS:
    -e, --environment ENV    Deployment environment: local, aws, azure (default: local)
    -p, --patients N         Number of patients to generate (default: 30)
    -r, --providers N        Number of providers to generate (default: 10)
    -o, --orgs N            Number of organizations to generate (default: 5)
    -f, --fresh             Fresh deployment (removes existing data)
    -d, --skip-dicom        Skip DICOM image generation
    -n, --skip-name-clean   Skip name cleaning
    -v, --verbose           Verbose output
    -h, --help              Show this help message

EXAMPLES:
    # Local deployment with 30 patients
    $0

    # Fresh AWS deployment with 50 patients
    $0 --environment aws --patients 50 --fresh

    # Quick local test with minimal data
    $0 --patients 5 --providers 2 --orgs 1 --skip-dicom

EOF
    exit 0
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -e|--environment)
                DEPLOYMENT_ENV="$2"
                shift 2
                ;;
            -p|--patients)
                PATIENT_COUNT="$2"
                shift 2
                ;;
            -r|--providers)
                PROVIDER_COUNT="$2"
                shift 2
                ;;
            -o|--orgs)
                ORGANIZATION_COUNT="$2"
                shift 2
                ;;
            -f|--fresh)
                FRESH_DEPLOY=true
                shift
                ;;
            -d|--skip-dicom)
                INCLUDE_DICOM=false
                shift
                ;;
            -n|--skip-name-clean)
                CLEAN_NAMES=false
                shift
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -h|--help)
                usage
                ;;
            *)
                log_error "Unknown option: $1"
                usage
                ;;
        esac
    done
}

# Check prerequisites
check_prerequisites() {
    log_section "Checking Prerequisites"
    
    local missing_deps=()
    
    # Check Docker
    if [[ "$DEPLOYMENT_ENV" == "local" ]]; then
        if ! command -v docker &> /dev/null; then
            missing_deps+=("Docker")
            log_error "Docker is not installed"
            echo "  Please install Docker Desktop from: https://www.docker.com/products/docker-desktop"
        else
            log_success "Docker is installed: $(docker --version)"
            
            # Check if Docker is running
            if ! docker info > /dev/null 2>&1; then
                log_error "Docker is not running. Please start Docker Desktop."
                exit 1
            fi
            log_success "Docker is running"
        fi
        
        # Check docker-compose
        if ! command -v docker-compose &> /dev/null; then
            # Try docker compose (newer version)
            if ! docker compose version &> /dev/null; then
                missing_deps+=("Docker Compose")
                log_error "Docker Compose is not installed"
            else
                log_success "Docker Compose is installed (docker compose)"
                # Create alias for consistency
                alias docker-compose="docker compose"
            fi
        else
            log_success "Docker Compose is installed: $(docker-compose --version)"
        fi
    fi
    
    # Check Git
    if ! command -v git &> /dev/null; then
        missing_deps+=("Git")
        log_error "Git is not installed"
    else
        log_success "Git is installed: $(git --version)"
    fi
    
    # Check curl
    if ! command -v curl &> /dev/null; then
        missing_deps+=("curl")
        log_error "curl is not installed"
    else
        log_success "curl is installed"
    fi
    
    # For AWS deployment
    if [[ "$DEPLOYMENT_ENV" == "aws" ]]; then
        if ! command -v aws &> /dev/null; then
            missing_deps+=("AWS CLI")
            log_warning "AWS CLI is not installed (optional but recommended)"
        else
            log_success "AWS CLI is installed"
        fi
    fi
    
    # For Azure deployment
    if [[ "$DEPLOYMENT_ENV" == "azure" ]]; then
        if ! command -v az &> /dev/null; then
            missing_deps+=("Azure CLI")
            log_warning "Azure CLI is not installed (optional but recommended)"
        else
            log_success "Azure CLI is installed"
        fi
    fi
    
    # Check if we have critical missing dependencies
    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        log_error "Missing critical dependencies: ${missing_deps[*]}"
        echo ""
        echo "Installation instructions:"
        echo "  - Docker: https://www.docker.com/products/docker-desktop"
        echo "  - Git: https://git-scm.com/downloads"
        echo "  - AWS CLI: https://aws.amazon.com/cli/"
        echo "  - Azure CLI: https://docs.microsoft.com/en-us/cli/azure/install-azure-cli"
        return 1
    fi
    
    return 0
}

# Create enhanced data generation script
create_data_enhancement_script() {
    log_info "Creating data enhancement script..."
    
    cat > backend/scripts/enhance_fhir_data.py << 'EOF'
#!/usr/bin/env python3
"""
Enhanced FHIR Data Generation
Creates Organizations, Providers, and cleans patient names
"""

import asyncio
import json
import random
import re
import uuid
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class FHIRDataEnhancer:
    def __init__(self, org_count: int = 5, provider_count: int = 10):
        self.org_count = org_count
        self.provider_count = provider_count
        
        # Realistic data for generation
        self.org_prefixes = ["City", "County", "Regional", "St.", "University", "Community"]
        self.org_suffixes = ["Hospital", "Medical Center", "Health System", "Clinic", "Healthcare"]
        
        self.first_names = {
            'male': ["James", "John", "Robert", "Michael", "William", "David", "Richard", 
                    "Joseph", "Thomas", "Charles", "Christopher", "Daniel", "Matthew"],
            'female': ["Mary", "Patricia", "Jennifer", "Linda", "Elizabeth", "Barbara", 
                      "Susan", "Jessica", "Sarah", "Karen", "Nancy", "Lisa", "Margaret"]
        }
        
        self.last_names = ["Smith", "Johnson", "Williams", "Brown", "Jones", "Garcia", 
                          "Miller", "Davis", "Rodriguez", "Martinez", "Hernandez", "Lopez",
                          "Gonzalez", "Wilson", "Anderson", "Thomas", "Taylor", "Moore"]
        
        self.specialties = [
            ("General Practice", "208D00000X", "394814009"),
            ("Internal Medicine", "207R00000X", "419192003"),
            ("Pediatrics", "208000000X", "394537008"),
            ("Cardiology", "207RC0000X", "394579002"),
            ("Emergency Medicine", "207P00000X", "773568002"),
            ("Family Medicine", "207Q00000X", "419772000"),
            ("Psychiatry", "2084P0800X", "394587001"),
            ("Surgery", "208600000X", "394609007")
        ]
        
        self.cities = {
            "MA": ["Boston", "Cambridge", "Worcester", "Springfield", "Lowell"],
            "NY": ["New York", "Buffalo", "Rochester", "Albany", "Syracuse"],
            "CA": ["Los Angeles", "San Francisco", "San Diego", "Sacramento", "San Jose"],
            "TX": ["Houston", "Dallas", "Austin", "San Antonio", "Fort Worth"],
            "IL": ["Chicago", "Aurora", "Rockford", "Joliet", "Naperville"]
        }
    
    def clean_name(self, name: str) -> str:
        """Clean synthetic names by removing numbers and test patterns"""
        if not name:
            return ""
        
        # Remove numeric suffixes
        name = re.sub(r'\d+$', '', name)
        # Remove test patterns
        name = re.sub(r'(test|synthetic|demo)', '', name, flags=re.IGNORECASE)
        # Clean up extra spaces and underscores
        name = re.sub(r'[_\-]+', ' ', name)
        name = re.sub(r'\s+', ' ', name)
        name = name.strip()
        
        # If name is empty or single character after cleaning, generate new one
        if len(name) < 2:
            return None
        
        # Proper case
        return ' '.join(word.capitalize() for word in name.split())
    
    def generate_organizations(self) -> List[Dict[str, Any]]:
        """Generate realistic Organization resources"""
        organizations = []
        states = list(self.cities.keys())
        
        for i in range(self.org_count):
            state = random.choice(states)
            city = random.choice(self.cities[state])
            
            org_name = f"{random.choice(self.org_prefixes)} {city} {random.choice(self.org_suffixes)}"
            
            org = {
                "resourceType": "Organization",
                "id": str(uuid.uuid4()),
                "meta": {
                    "lastUpdated": datetime.utcnow().isoformat() + "Z"
                },
                "identifier": [{
                    "system": "http://hl7.org/fhir/sid/us-npi",
                    "value": f"1{random.randint(100000000, 999999999)}"
                }],
                "active": True,
                "type": [{
                    "coding": [{
                        "system": "http://terminology.hl7.org/CodeSystem/organization-type",
                        "code": "prov",
                        "display": "Healthcare Provider"
                    }]
                }],
                "name": org_name,
                "telecom": [
                    {
                        "system": "phone",
                        "value": f"({random.randint(200, 999)}) {random.randint(200, 999)}-{random.randint(1000, 9999)}",
                        "use": "work"
                    },
                    {
                        "system": "fax",
                        "value": f"({random.randint(200, 999)}) {random.randint(200, 999)}-{random.randint(1000, 9999)}",
                        "use": "work"
                    }
                ],
                "address": [{
                    "use": "work",
                    "type": "physical",
                    "line": [f"{random.randint(1, 9999)} {random.choice(['Main', 'Oak', 'Elm', 'Park', 'Washington'])} Street"],
                    "city": city,
                    "state": state,
                    "postalCode": f"{random.randint(10000, 99999)}",
                    "country": "USA"
                }]
            }
            
            organizations.append(org)
            logger.info(f"Generated Organization: {org_name}")
        
        return organizations
    
    def generate_providers(self, org_ids: List[str]) -> List[Dict[str, Any]]:
        """Generate realistic Practitioner resources"""
        practitioners = []
        
        for i in range(self.provider_count):
            gender = random.choice(['male', 'female'])
            first_name = random.choice(self.first_names[gender])
            last_name = random.choice(self.last_names)
            
            practitioner = {
                "resourceType": "Practitioner",
                "id": str(uuid.uuid4()),
                "meta": {
                    "lastUpdated": datetime.utcnow().isoformat() + "Z"
                },
                "identifier": [
                    {
                        "system": "http://hl7.org/fhir/sid/us-npi",
                        "value": f"2{random.randint(100000000, 999999999)}"
                    },
                    {
                        "system": "http://example.org/license",
                        "value": f"MD-{state}-{random.randint(10000, 99999)}"
                    }
                ],
                "active": True,
                "name": [{
                    "use": "official",
                    "family": last_name,
                    "given": [first_name],
                    "prefix": ["Dr."]
                }],
                "telecom": [{
                    "system": "phone",
                    "value": f"({random.randint(200, 999)}) {random.randint(200, 999)}-{random.randint(1000, 9999)}",
                    "use": "work"
                }],
                "gender": gender,
                "birthDate": (datetime.now() - timedelta(days=random.randint(10950, 21900))).strftime("%Y-%m-%d"),
                "qualification": [{
                    "identifier": [{
                        "system": "http://example.org/UniversityID",
                        "value": f"MD-{random.randint(1970, 2015)}"
                    }],
                    "code": {
                        "coding": [{
                            "system": "http://terminology.hl7.org/CodeSystem/v2-0360",
                            "code": "MD",
                            "display": "Doctor of Medicine"
                        }]
                    },
                    "issuer": {
                        "display": f"{random.choice(['Harvard', 'Johns Hopkins', 'Stanford', 'Yale', 'Columbia'])} Medical School"
                    }
                }]
            }
            
            practitioners.append(practitioner)
            logger.info(f"Generated Practitioner: Dr. {first_name} {last_name}")
        
        return practitioners
    
    def generate_practitioner_roles(self, practitioner_ids: List[str], org_ids: List[str]) -> List[Dict[str, Any]]:
        """Generate PractitionerRole resources linking practitioners to organizations"""
        roles = []
        
        for practitioner_id in practitioner_ids:
            org_id = random.choice(org_ids)
            specialty = random.choice(self.specialties)
            
            role = {
                "resourceType": "PractitionerRole",
                "id": str(uuid.uuid4()),
                "meta": {
                    "lastUpdated": datetime.utcnow().isoformat() + "Z"
                },
                "active": True,
                "period": {
                    "start": (datetime.now() - timedelta(days=random.randint(365, 3650))).strftime("%Y-%m-%d")
                },
                "practitioner": {
                    "reference": f"Practitioner/{practitioner_id}"
                },
                "organization": {
                    "reference": f"Organization/{org_id}"
                },
                "code": [{
                    "coding": [{
                        "system": "http://nucc.org/provider-taxonomy",
                        "code": specialty[1],
                        "display": specialty[0]
                    }]
                }],
                "specialty": [{
                    "coding": [{
                        "system": "http://snomed.info/sct",
                        "code": specialty[2],
                        "display": specialty[0]
                    }]
                }],
                "availableTime": [{
                    "daysOfWeek": ["mon", "tue", "wed", "thu", "fri"],
                    "availableStartTime": "09:00:00",
                    "availableEndTime": "17:00:00"
                }]
            }
            
            roles.append(role)
        
        return roles
    
    async def process_existing_patients(self) -> Dict[str, Any]:
        """Clean names of existing patients and assign providers"""
        import aiohttp
        
        cleaned_count = 0
        assigned_count = 0
        
        async with aiohttp.ClientSession() as session:
            # Get all patients
            async with session.get("http://localhost:8000/fhir/R4/Patient?_count=1000") as response:
                if response.status != 200:
                    logger.error(f"Failed to fetch patients: {response.status}")
                    return {"cleaned": 0, "assigned": 0}
                
                bundle = await response.json()
                patients = [entry["resource"] for entry in bundle.get("entry", [])]
                
                # Get available practitioners
                async with session.get("http://localhost:8000/fhir/R4/Practitioner?_count=1000") as prac_response:
                    if prac_response.status == 200:
                        prac_bundle = await prac_response.json()
                        practitioners = [entry["resource"]["id"] for entry in prac_bundle.get("entry", [])]
                    else:
                        practitioners = []
                
                # Process each patient
                for patient in patients:
                    patient_id = patient.get("id")
                    modified = False
                    
                    # Clean names
                    if "name" in patient:
                        for name in patient["name"]:
                            # Clean family name
                            if "family" in name:
                                cleaned_family = self.clean_name(name["family"])
                                if cleaned_family and cleaned_family != name["family"]:
                                    name["family"] = cleaned_family
                                    modified = True
                                elif not cleaned_family:
                                    name["family"] = random.choice(self.last_names)
                                    modified = True
                            
                            # Clean given names
                            if "given" in name:
                                cleaned_given = []
                                for given_name in name["given"]:
                                    cleaned = self.clean_name(given_name)
                                    if cleaned:
                                        cleaned_given.append(cleaned)
                                    else:
                                        # Generate new first name based on gender
                                        gender = patient.get("gender", "male")
                                        cleaned_given.append(random.choice(self.first_names.get(gender, self.first_names["male"])))
                                
                                if cleaned_given != name["given"]:
                                    name["given"] = cleaned_given
                                    modified = True
                    
                    # Assign general practitioner if not present
                    if practitioners and not patient.get("generalPractitioner"):
                        patient["generalPractitioner"] = [{
                            "reference": f"Practitioner/{random.choice(practitioners)}"
                        }]
                        modified = True
                        assigned_count += 1
                    
                    # Update patient if modified
                    if modified:
                        async with session.put(
                            f"http://localhost:8000/fhir/R4/Patient/{patient_id}",
                            json=patient,
                            headers={"Content-Type": "application/fhir+json"}
                        ) as update_response:
                            if update_response.status == 200:
                                cleaned_count += 1
                                logger.info(f"Updated patient {patient_id}")
                            else:
                                logger.error(f"Failed to update patient {patient_id}: {update_response.status}")
        
        return {"cleaned": cleaned_count, "assigned": assigned_count}
    
    async def generate_all(self) -> Dict[str, Any]:
        """Generate all enhanced data and return as transaction bundle"""
        logger.info("Starting enhanced FHIR data generation...")
        
        # Generate organizations
        organizations = self.generate_organizations()
        org_ids = [org["id"] for org in organizations]
        
        # Generate practitioners
        practitioners = self.generate_providers(org_ids)
        practitioner_ids = [prac["id"] for prac in practitioners]
        
        # Generate practitioner roles
        roles = self.generate_practitioner_roles(practitioner_ids, org_ids)
        
        # Create transaction bundle
        bundle = {
            "resourceType": "Bundle",
            "type": "transaction",
            "entry": []
        }
        
        # Add organizations
        for org in organizations:
            bundle["entry"].append({
                "resource": org,
                "request": {
                    "method": "POST",
                    "url": "Organization"
                }
            })
        
        # Add practitioners
        for prac in practitioners:
            bundle["entry"].append({
                "resource": prac,
                "request": {
                    "method": "POST",
                    "url": "Practitioner"
                }
            })
        
        # Add practitioner roles
        for role in roles:
            bundle["entry"].append({
                "resource": role,
                "request": {
                    "method": "POST",
                    "url": "PractitionerRole"
                }
            })
        
        logger.info(f"Generated bundle with {len(bundle['entry'])} resources")
        
        # Save bundle for reference
        with open("/app/scripts/data/enhanced_resources.json", "w") as f:
            json.dump(bundle, f, indent=2)
        
        return bundle

async def main():
    import sys
    
    org_count = int(sys.argv[1]) if len(sys.argv) > 1 else 5
    provider_count = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    enhancer = FHIRDataEnhancer(org_count, provider_count)
    
    # Generate new resources
    bundle = await enhancer.generate_all()
    
    # Submit bundle to FHIR server
    import aiohttp
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://localhost:8000/fhir/R4/",
            json=bundle,
            headers={"Content-Type": "application/fhir+json"}
        ) as response:
            if response.status == 200:
                result = await response.json()
                logger.info("âœ… Successfully loaded enhanced resources")
            else:
                error = await response.text()
                logger.error(f"âŒ Failed to load resources: {error}")
                return
    
    # Process existing patients
    logger.info("Processing existing patients...")
    stats = await enhancer.process_existing_patients()
    logger.info(f"âœ… Cleaned {stats['cleaned']} patient names")
    logger.info(f"âœ… Assigned {stats['assigned']} patients to practitioners")

if __name__ == "__main__":
    asyncio.run(main())
EOF
    
    chmod +x backend/scripts/enhance_fhir_data.py
    log_success "Data enhancement script created"
}

# Deploy for local environment
deploy_local() {
    log_section "Local Docker Deployment"
    
    # Clean up if fresh deployment
    if [[ "$FRESH_DEPLOY" == true ]]; then
        log_warning "Performing fresh deployment - removing existing data..."
        docker-compose down -v 2>/dev/null || true
        docker system prune -f > /dev/null 2>&1 || true
        rm -rf backend/data/generated_dicoms/* 2>/dev/null || true
        rm -rf synthea/output/fhir/*.json 2>/dev/null || true
    fi
    
    # Ensure directories exist
    log_info "Creating necessary directories..."
    mkdir -p backend/scripts/data
    mkdir -p backend/data/generated_dicoms
    mkdir -p backend/logs
    mkdir -p data
    mkdir -p logs
    
    # Create data enhancement script
    create_data_enhancement_script
    
    # Build containers
    log_info "Building Docker containers..."
    docker-compose build
    
    # Start services
    log_info "Starting services..."
    docker-compose up -d
    
    # Wait for services
    log_info "Waiting for services to be ready..."
    local max_attempts=30
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        if curl -s http://localhost:8000/health > /dev/null 2>&1; then
            log_success "Backend is healthy"
            
            # Always ensure database is properly initialized
            log_info "Ensuring database is fully initialized..."
            docker-compose exec -T backend python scripts/init_complete_database.py || {
                log_warning "Database initialization had issues, but continuing..."
            }
            
            break
        fi
        attempt=$((attempt + 1))
        if [ $attempt -eq $max_attempts ]; then
            log_error "Backend failed to start after ${max_attempts} attempts"
            docker-compose logs backend
            exit 1
        fi
        sleep 2
    done
    
    # Additional wait for full initialization
    sleep 5
    
    # Generate Synthea data
    log_section "Generating FHIR Data"
    log_info "Generating ${PATIENT_COUNT} patients with Synthea..."
    
    local synthea_args="--count ${PATIENT_COUNT}"
    if [[ "$INCLUDE_DICOM" == true ]]; then
        synthea_args="$synthea_args --include-dicom"
    fi
    if [[ "$CLEAN_NAMES" == true ]]; then
        synthea_args="$synthea_args --clean-names"
    fi
    
    docker-compose exec -T backend python scripts/synthea_master.py full $synthea_args || {
        log_error "Failed to generate Synthea data"
        exit 1
    }
    
    # Ensure database is fully initialized
    log_info "Verifying database initialization..."
    
    # Wait a bit more for PostgreSQL init scripts to complete
    sleep 10
    
    # Verify database schema is properly initialized
    docker-compose exec -T backend python -c "
import asyncio
import asyncpg
import sys

async def verify_schema():
    try:
        conn = await asyncpg.connect('postgresql://emr_user:emr_password@postgres:5432/emr_db')
        
        # Check all critical tables exist
        tables = await conn.fetch('''
            SELECT table_name FROM information_schema.tables 
            WHERE table_schema = 'fhir' 
            AND table_name IN ('resources', 'search_params', 'resource_history', 'references', 'compartments', 'audit_logs')
        ''')
        
        table_names = {row['table_name'] for row in tables}
        required_tables = {'resources', 'search_params', 'resource_history', 'references', 'compartments', 'audit_logs'}
        
        if required_tables.issubset(table_names):
            print('âœ… Database schema fully initialized')
            await conn.close()
            return True
        else:
            missing = required_tables - table_names
            print(f'âŒ Missing tables: {missing}')
            print('âš ï¸  Running manual database initialization...')
            await conn.close()
            return False
    except Exception as e:
        print(f'âŒ Schema verification failed: {e}')
        return False

success = asyncio.run(verify_schema())
sys.exit(0 if success else 1)
" || {
        log_warning "Database schema not fully initialized, running manual setup..."
        
        # Run manual database initialization as fallback
        docker-compose exec -T backend python scripts/init_complete_database.py || {
            log_error "Manual database initialization failed"
            exit 1
        }
    }
    
    # Clean names after data import (this will be done later, after Synthea import)
    log_info "Database initialization verified"
    
    # Generate and load enhanced data (Organizations, Providers)
    log_info "Generating ${ORGANIZATION_COUNT} organizations and ${PROVIDER_COUNT} providers..."
    docker-compose exec -T backend python scripts/enhance_fhir_data.py ${ORGANIZATION_COUNT} ${PROVIDER_COUNT} 2>/dev/null || {
        log_warning "Enhanced data generation had issues (this is expected due to validation), but continuing..."
    }
    
    # Clean up data after import
    log_info "Cleaning patient and provider names, fixing references..."
    docker-compose exec -T backend python -c "
import asyncio
import asyncpg
import re
import json

async def cleanup_data():
    conn = await asyncpg.connect('postgresql://emr_user:emr_password@postgres:5432/emr_db')
    
    # Clean patient names
    patients = await conn.fetch('SELECT id, resource FROM fhir.resources WHERE resource_type = \\'Patient\\' AND deleted = false')
    patient_count = 0
    
    for patient in patients:
        resource = patient['resource']
        modified = False
        
        if 'name' in resource:
            for name in resource['name']:
                if 'given' in name:
                    cleaned_given = [re.sub(r'\\d+\$', '', n).strip() or n for n in name['given']]
                    if cleaned_given != name['given']:
                        name['given'] = cleaned_given
                        modified = True
                
                if 'family' in name:
                    original = name['family']
                    cleaned = re.sub(r'\\d+\$', '', original).strip()
                    if cleaned and cleaned != original:
                        name['family'] = cleaned
                        modified = True
        
        if modified:
            await conn.execute('UPDATE fhir.resources SET resource = \$1, version_id = version_id + 1, last_updated = CURRENT_TIMESTAMP WHERE id = \$2', json.dumps(resource), patient['id'])
            patient_count += 1
    
    print(f'âœ… Cleaned {patient_count} patient names')
    
    # Clean practitioner names  
    practitioners = await conn.fetch('SELECT id, resource FROM fhir.resources WHERE resource_type = \\'Practitioner\\' AND deleted = false')
    practitioner_count = 0
    
    for practitioner in practitioners:
        resource = practitioner['resource']
        modified = False
        
        if 'name' in resource:
            for name in resource['name']:
                if 'given' in name:
                    cleaned_given = [re.sub(r'\\d+\$', '', n).strip() or n for n in name['given']]
                    if cleaned_given != name['given']:
                        name['given'] = cleaned_given
                        modified = True
                
                if 'family' in name:
                    original = name['family']
                    cleaned = re.sub(r'\\d+\$', '', original).strip()
                    if cleaned and cleaned != original:
                        name['family'] = cleaned
                        modified = True
        
        if modified:
            await conn.execute('UPDATE fhir.resources SET resource = \$1, version_id = version_id + 1, last_updated = CURRENT_TIMESTAMP WHERE id = \$2', json.dumps(resource), practitioner['id'])
            practitioner_count += 1
    
    print(f'âœ… Cleaned {practitioner_count} practitioner names')
    await conn.close()

asyncio.run(cleanup_data())
" || {
        log_warning "Data cleanup had issues, but continuing..."
    }
    
    # Verify data
    log_section "Verifying Data Generation"
    
    echo -n "Patients: "
    docker-compose exec -T backend python -c "
import asyncio
import asyncpg
async def count():
    conn = await asyncpg.connect('postgresql://emr_user:emr_password@postgres:5432/emr_db')
    count = await conn.fetchval('SELECT COUNT(*) FROM fhir.resources WHERE resource_type = \\'Patient\\' AND deleted = false')
    print(count)
    await conn.close()
asyncio.run(count())
" || echo "0"
    
    echo -n "Organizations: "
    docker-compose exec -T backend python -c "
import asyncio
import asyncpg
async def count():
    conn = await asyncpg.connect('postgresql://emr_user:emr_password@postgres:5432/emr_db')
    count = await conn.fetchval('SELECT COUNT(*) FROM fhir.resources WHERE resource_type = \\'Organization\\' AND deleted = false')
    print(count)
    await conn.close()
asyncio.run(count())
" || echo "0"
    
    echo -n "Practitioners: "
    docker-compose exec -T backend python -c "
import asyncio
import asyncpg
async def count():
    conn = await asyncpg.connect('postgresql://emr_user:emr_password@postgres:5432/emr_db')
    count = await conn.fetchval('SELECT COUNT(*) FROM fhir.resources WHERE resource_type = \\'Practitioner\\' AND deleted = false')
    print(count)
    await conn.close()
asyncio.run(count())
" || echo "0"
    
    # Fix static file permissions
    log_info "Fixing static file permissions..."
    docker-compose exec frontend chmod 644 /usr/share/nginx/html/manifest.json /usr/share/nginx/html/favicon.ico 2>/dev/null || {
        log_warning "Could not fix static file permissions - files may not exist yet"
    }
    
    # Run validation tests
    if [[ "$VERBOSE" == true ]]; then
        log_info "Running comprehensive validation tests..."
        docker-compose exec -T backend python test_fhir_comprehensive.py || {
            log_warning "Some tests failed - this is expected during initial setup"
        }
    fi
}

# Deploy for AWS
deploy_aws() {
    log_section "AWS Deployment"
    log_warning "AWS deployment requires additional setup"
    echo "Please ensure you have:"
    echo "  - AWS CLI configured with credentials"
    echo "  - EC2 instance or ECS cluster ready"
    echo "  - RDS PostgreSQL instance configured"
    echo ""
    echo "For detailed AWS deployment, use:"
    echo "  ./deployment/aws/deploy-ec2-production.sh"
}

# Deploy for Azure
deploy_azure() {
    log_section "Azure Deployment"
    log_warning "Azure deployment requires additional setup"
    echo "Please ensure you have:"
    echo "  - Azure CLI configured with credentials"
    echo "  - Resource group created"
    echo "  - Azure Database for PostgreSQL configured"
    echo ""
    echo "For detailed Azure deployment, use:"
    echo "  ./deployment/azure/deploy-azure-production.sh"
}

# Main deployment orchestration
main() {
    echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${BLUE}â•‘          ğŸ¥ MedGenEMR Unified Deployment ğŸ¥           â•‘${NC}"
    echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    
    # Check prerequisites
    if ! check_prerequisites; then
        exit 1
    fi
    
    # Deploy based on environment
    case $DEPLOYMENT_ENV in
        local)
            deploy_local
            ;;
        aws)
            deploy_aws
            ;;
        azure)
            deploy_azure
            ;;
        *)
            log_error "Unknown deployment environment: $DEPLOYMENT_ENV"
            exit 1
            ;;
    esac
    
    # Show summary
    if [[ "$DEPLOYMENT_ENV" == "local" ]]; then
        log_section "Deployment Complete! ğŸ‰"
        echo -e "${GREEN}Access Points:${NC}"
        echo "  ğŸŒ Frontend:    http://localhost"
        echo "  ğŸ”§ Backend API: http://localhost:8000"
        echo "  ğŸ“š API Docs:    http://localhost:8000/docs"
        echo "  ğŸ” FHIR API:    http://localhost:8000/fhir/R4"
        echo ""
        echo -e "${GREEN}Login Credentials:${NC}"
        echo "  Username: demo"
        echo "  Password: password"
        echo ""
        echo -e "${GREEN}Generated Data:${NC}"
        echo "  - ${PATIENT_COUNT} patients with cleaned names"
        echo "  - ${PROVIDER_COUNT} healthcare providers"
        echo "  - ${ORGANIZATION_COUNT} healthcare organizations"
        if [[ "$INCLUDE_DICOM" == true ]]; then
            echo "  - DICOM imaging studies"
        fi
        echo ""
        echo -e "${YELLOW}Useful Commands:${NC}"
        echo "  View logs:        docker-compose logs -f"
        echo "  Stop services:    docker-compose down"
        echo "  Clean everything: docker-compose down -v"
        echo "  Run tests:        docker-compose exec backend python run_all_tests.py"
        echo ""
        
        # Optionally open browser
        if command -v open > /dev/null 2>&1; then
            log_info "Opening MedGenEMR in browser..."
            sleep 2
            open http://localhost
        elif command -v xdg-open > /dev/null 2>&1; then
            xdg-open http://localhost
        fi
    fi
}

# Parse arguments and run
parse_args "$@"
main